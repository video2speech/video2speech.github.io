#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os
from difflib import SequenceMatcher
from itertools import combinations
import re

class SentenceSimilarityChecker:
    def __init__(self):
        self.sentences = []
        self.load_sentences()
    
    def load_sentences(self):
        """åŠ è½½å¥å­æ•°æ®"""
        sentences_file = "selected_sentences_analyzer.json"
        if os.path.exists(sentences_file):
            try:
                with open(sentences_file, 'r', encoding='utf-8') as f:
                    self.sentences = json.load(f)
                print(f"ğŸ“ åŠ è½½äº† {len(self.sentences)} ä¸ªå¥å­")
            except:
                print("âŒ åŠ è½½å¥å­æ–‡ä»¶å¤±è´¥")
                self.sentences = []
        else:
            print("âŒ æœªæ‰¾åˆ° selected_sentences_analyzer.json æ–‡ä»¶")
            self.sentences = []
    
    def clean_for_comparison(self, sentence):
        """æ¸…ç†å¥å­ç”¨äºæ¯”è¾ƒï¼ˆå»é™¤æ ‡ç‚¹ï¼Œç»Ÿä¸€å¤§å°å†™ï¼‰"""
        # è½¬å°å†™
        sentence = sentence.lower()
        # å»é™¤æ ‡ç‚¹ç¬¦å·
        sentence = re.sub(r'[^\w\s]', '', sentence)
        # å»é™¤å¤šä½™ç©ºæ ¼
        sentence = re.sub(r'\s+', ' ', sentence).strip()
        return sentence
    
    def calculate_similarity(self, sent1, sent2):
        """è®¡ç®—ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼åº¦"""
        # æ¸…ç†å¥å­
        clean1 = self.clean_for_comparison(sent1)
        clean2 = self.clean_for_comparison(sent2)
        
        # ä½¿ç”¨ SequenceMatcher è®¡ç®—ç›¸ä¼¼åº¦
        similarity = SequenceMatcher(None, clean1, clean2).ratio()
        return similarity
    
    def word_overlap_similarity(self, sent1, sent2):
        """è®¡ç®—è¯æ±‡é‡å ç›¸ä¼¼åº¦"""
        words1 = set(self.clean_for_comparison(sent1).split())
        words2 = set(self.clean_for_comparison(sent2).split())
        
        if not words1 and not words2:
            return 1.0
        if not words1 or not words2:
            return 0.0
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        return intersection / union if union > 0 else 0.0
    
    def analyze_similarity(self):
        """åˆ†ææ‰€æœ‰å¥å­å¯¹çš„ç›¸ä¼¼åº¦"""
        if len(self.sentences) < 2:
            print("âŒ éœ€è¦è‡³å°‘2ä¸ªå¥å­æ‰èƒ½è¿›è¡Œç›¸ä¼¼åº¦åˆ†æ")
            return
        
        print(f"\nğŸ” åˆ†æ {len(self.sentences)} ä¸ªå¥å­çš„ç›¸ä¼¼åº¦...")
        print(f"æ€»å…±éœ€è¦æ¯”è¾ƒ {len(self.sentences) * (len(self.sentences) - 1) // 2} å¯¹å¥å­")
        
        similarities = []
        
        # è®¡ç®—æ‰€æœ‰å¥å­å¯¹çš„ç›¸ä¼¼åº¦
        for i, j in combinations(range(len(self.sentences)), 2):
            sent1 = self.sentences[i]
            sent2 = self.sentences[j]
            
            # å­—ç¬¦åºåˆ—ç›¸ä¼¼åº¦
            char_sim = self.calculate_similarity(sent1, sent2)
            # è¯æ±‡é‡å ç›¸ä¼¼åº¦
            word_sim = self.word_overlap_similarity(sent1, sent2)
            # ç»¼åˆç›¸ä¼¼åº¦ï¼ˆå­—ç¬¦ç›¸ä¼¼åº¦å’Œè¯æ±‡ç›¸ä¼¼åº¦çš„å¹³å‡å€¼ï¼‰
            combined_sim = (char_sim + word_sim) / 2
            
            similarities.append({
                'index1': i + 1,
                'index2': j + 1,
                'sentence1': sent1,
                'sentence2': sent2,
                'char_similarity': char_sim,
                'word_similarity': word_sim,
                'combined_similarity': combined_sim
            })
        
        # æŒ‰ç»¼åˆç›¸ä¼¼åº¦æ’åºï¼ˆä»é«˜åˆ°ä½ï¼‰
        similarities.sort(key=lambda x: x['combined_similarity'], reverse=True)
        
        return similarities
    
    def display_results(self, similarities, top_n=20):
        """æ˜¾ç¤ºç›¸ä¼¼åº¦åˆ†æç»“æœ"""
        print("\n" + "=" * 100)
        print("ğŸ“Š å¥å­ç›¸ä¼¼åº¦åˆ†æç»“æœ (æŒ‰ç›¸ä¼¼åº¦æ’åº)")
        print("=" * 100)
        
        print(f"\nğŸ” æ˜¾ç¤ºå‰ {min(top_n, len(similarities))} ä¸ªæœ€ç›¸ä¼¼çš„å¥å­å¯¹:")
        print("-" * 100)
        
        for i, sim in enumerate(similarities[:top_n], 1):
            print(f"\n#{i:2d} ç›¸ä¼¼åº¦: {sim['combined_similarity']:.3f} (å­—ç¬¦: {sim['char_similarity']:.3f}, è¯æ±‡: {sim['word_similarity']:.3f})")
            print(f"    å¥å­ {sim['index1']:2d}: {sim['sentence1']}")
            print(f"    å¥å­ {sim['index2']:2d}: {sim['sentence2']}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“ˆ ç»Ÿè®¡æ‘˜è¦:")
        print(f"   æ€»å¥å­å¯¹æ•°: {len(similarities)}")
        high_sim = sum(1 for s in similarities if s['combined_similarity'] > 0.8)
        medium_sim = sum(1 for s in similarities if 0.5 < s['combined_similarity'] <= 0.8)
        low_sim = sum(1 for s in similarities if s['combined_similarity'] <= 0.5)
        
        print(f"   é«˜ç›¸ä¼¼åº¦ (>0.8): {high_sim} å¯¹ ({high_sim/len(similarities)*100:.1f}%)")
        print(f"   ä¸­ç›¸ä¼¼åº¦ (0.5-0.8): {medium_sim} å¯¹ ({medium_sim/len(similarities)*100:.1f}%)")
        print(f"   ä½ç›¸ä¼¼åº¦ (â‰¤0.5): {low_sim} å¯¹ ({low_sim/len(similarities)*100:.1f}%)")
        
        avg_sim = sum(s['combined_similarity'] for s in similarities) / len(similarities)
        print(f"   å¹³å‡ç›¸ä¼¼åº¦: {avg_sim:.3f}")
    
    def find_duplicates(self, threshold=0.9):
        """æŸ¥æ‰¾å¯èƒ½çš„é‡å¤å¥å­"""
        similarities = self.analyze_similarity()
        if not similarities:
            return
        
        duplicates = [s for s in similarities if s['combined_similarity'] >= threshold]
        
        print(f"\nğŸ” å¯èƒ½çš„é‡å¤å¥å­ (ç›¸ä¼¼åº¦ â‰¥ {threshold}):")
        print("-" * 80)
        
        if duplicates:
            for i, dup in enumerate(duplicates, 1):
                print(f"\n#{i} ç›¸ä¼¼åº¦: {dup['combined_similarity']:.3f}")
                print(f"   å¥å­ {dup['index1']}: {dup['sentence1']}")
                print(f"   å¥å­ {dup['index2']}: {dup['sentence2']}")
        else:
            print("   æœªå‘ç°é«˜åº¦ç›¸ä¼¼çš„å¥å­")
        
        return duplicates
    
    def save_results(self, similarities, filename="sentence_similarity_report.txt"):
        """ä¿å­˜ç›¸ä¼¼åº¦åˆ†æç»“æœåˆ°æ–‡ä»¶"""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("å¥å­ç›¸ä¼¼åº¦åˆ†ææŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"æ€»å¥å­æ•°: {len(self.sentences)}\n")
            f.write(f"æ€»å¥å­å¯¹æ•°: {len(similarities)}\n\n")
            
            f.write("æ‰€æœ‰å¥å­å¯¹çš„ç›¸ä¼¼åº¦ (æŒ‰ç›¸ä¼¼åº¦æ’åº):\n")
            f.write("-" * 50 + "\n")
            
            for i, sim in enumerate(similarities, 1):
                f.write(f"\n#{i:3d} ç›¸ä¼¼åº¦: {sim['combined_similarity']:.3f} ")
                f.write(f"(å­—ç¬¦: {sim['char_similarity']:.3f}, è¯æ±‡: {sim['word_similarity']:.3f})\n")
                f.write(f"      å¥å­ {sim['index1']:2d}: {sim['sentence1']}\n")
                f.write(f"      å¥å­ {sim['index2']:2d}: {sim['sentence2']}\n")
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ° {filename}")

def main():
    checker = SentenceSimilarityChecker()
    
    if not checker.sentences:
        return
    
    print("\nğŸ¯ å¥å­ç›¸ä¼¼åº¦æ£€æŸ¥å·¥å…·")
    print("=" * 50)
    print("ğŸ’¡ åŠŸèƒ½é€‰é¡¹:")
    print("   1. æ˜¾ç¤ºæœ€ç›¸ä¼¼çš„å¥å­å¯¹")
    print("   2. æŸ¥æ‰¾å¯èƒ½çš„é‡å¤å¥å­")
    print("   3. ä¿å­˜å®Œæ•´åˆ†ææŠ¥å‘Š")
    print("   4. é€€å‡º")
    
    while True:
        choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (1-4): ").strip()
        
        if choice == '1':
            similarities = checker.analyze_similarity()
            if similarities:
                try:
                    top_n = int(input("æ˜¾ç¤ºå‰å‡ ä¸ªæœ€ç›¸ä¼¼çš„å¥å­å¯¹ (é»˜è®¤20): ") or "20")
                    checker.display_results(similarities, top_n)
                except ValueError:
                    checker.display_results(similarities)
        
        elif choice == '2':
            try:
                threshold = float(input("ç›¸ä¼¼åº¦é˜ˆå€¼ (é»˜è®¤0.9): ") or "0.9")
                checker.find_duplicates(threshold)
            except ValueError:
                checker.find_duplicates()
        
        elif choice == '3':
            similarities = checker.analyze_similarity()
            if similarities:
                filename = input("ä¿å­˜æ–‡ä»¶å (é»˜è®¤sentence_similarity_report.txt): ").strip()
                if not filename:
                    filename = "sentence_similarity_report.txt"
                checker.save_results(similarities, filename)
        
        elif choice == '4':
            print("ğŸ‘‹ å†è§!")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-4")

if __name__ == "__main__":
    main()


