#!/usr/bin/env python3
"""
ä» movie_lines.tsv ä¸­æå–ç¬¦åˆæ¡ä»¶çš„å¥å­
æ¡ä»¶ï¼šå¥å­é•¿åº¦>=3ä¸ªè¯æ±‡ï¼Œä¸”æ¯ä¸ªè¯æ±‡éƒ½åœ¨PICK.txtä¸­
"""

import re
import string

def load_pick_words():
    """åŠ è½½PICK.txtä¸­çš„è¯æ±‡"""
    with open('/Users/terry/Downloads/video2speech.github.io/video2speech.github.io/PICK.txt', 'r', encoding='utf-8') as f:
        words = set()
        for line in f:
            word = line.strip()
            if word:
                words.add(word.lower())  # è½¬æ¢ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
        return words

def clean_and_split_text(text):
    """æ¸…ç†æ–‡æœ¬å¹¶åˆ†å‰²æˆå¥å­"""
    # ç§»é™¤å¼•å·å’Œå…¶ä»–æ ‡ç‚¹ç¬¦å·ï¼Œä½†ä¿ç•™å¥å­åˆ†éš”ç¬¦
    text = text.replace('"', '').replace("'", "'")
    
    # æŒ‰å¥å­åˆ†éš”ç¬¦åˆ†å‰²
    sentences = re.split(r'[.!?]+', text)
    
    cleaned_sentences = []
    for sentence in sentences:
        sentence = sentence.strip()
        if sentence:
            cleaned_sentences.append(sentence)
    
    return cleaned_sentences

def extract_words_from_sentence(sentence):
    """ä»å¥å­ä¸­æå–å•è¯"""
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œä¿ç•™å•è¯å’Œç©ºæ ¼
    # å¤„ç†ç¼©å†™å½¢å¼
    sentence = sentence.replace("'t", " not")  # don't -> do not
    sentence = sentence.replace("'re", " are")  # you're -> you are  
    sentence = sentence.replace("'ll", " will")  # I'll -> I will
    sentence = sentence.replace("'ve", " have")  # I've -> I have
    sentence = sentence.replace("'d", " would")  # I'd -> I would
    sentence = sentence.replace("'m", " am")  # I'm -> I am
    sentence = sentence.replace("'s", " is")  # it's -> it is
    
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·
    translator = str.maketrans('', '', string.punctuation)
    sentence = sentence.translate(translator)
    
    # åˆ†å‰²å•è¯å¹¶è½¬æ¢ä¸ºå°å†™
    words = sentence.lower().split()
    
    return words

def check_sentence_matches(sentence, pick_words):
    """æ£€æŸ¥å¥å­æ˜¯å¦ç¬¦åˆæ¡ä»¶"""
    words = extract_words_from_sentence(sentence)
    
    # æ£€æŸ¥é•¿åº¦æ˜¯å¦>=3
    if len(words) < 3:
        return False
    
    # æ£€æŸ¥æ¯ä¸ªè¯æ±‡æ˜¯å¦éƒ½åœ¨PICK.txtä¸­
    for word in words:
        if word not in pick_words:
            return False
    
    return True

def process_movie_lines():
    """å¤„ç†movie_lines.tsvæ–‡ä»¶"""
    print("ğŸ¬ å¼€å§‹å¤„ç† movie_lines.tsv...")
    
    # åŠ è½½PICKè¯æ±‡
    pick_words = load_pick_words()
    print(f"ğŸ“ åŠ è½½äº† {len(pick_words)} ä¸ªPICKè¯æ±‡")
    
    matching_sentences = []
    seen_sentences = set()  # ç”¨äºå»é‡
    total_lines = 0
    total_sentences = 0
    
    # å¤„ç†movie_lines.tsv
    with open('/Users/terry/Downloads/video2speech.github.io/video2speech.github.io/materials/movie_lines.tsv', 'r', encoding='utf-8', errors='ignore') as f:
        for line_num, line in enumerate(f, 1):
            total_lines += 1
            
            if line_num % 10000 == 0:
                print(f"ğŸ“Š å¤„ç†è¿›åº¦: {line_num} è¡Œ, æ‰¾åˆ° {len(matching_sentences)} ä¸ªåŒ¹é…å¥å­")
            
            # è§£æTSVæ ¼å¼ï¼šL1045	u0	m0	BIANCA	They do not!
            parts = line.strip().split('\t')
            if len(parts) >= 5:
                dialogue = parts[4]  # å¯¹è¯å†…å®¹
                
                # åˆ†å‰²æˆå¥å­
                sentences = clean_and_split_text(dialogue)
                total_sentences += len(sentences)
                
                for sentence in sentences:
                    # æ£€æŸ¥æ˜¯å¦ç¬¦åˆæ¡ä»¶
                    if check_sentence_matches(sentence, pick_words):
                        # å»é‡æ£€æŸ¥
                        sentence_lower = sentence.lower().strip()
                        if sentence_lower not in seen_sentences:
                            seen_sentences.add(sentence_lower)
                            matching_sentences.append(sentence.strip())
    
    print(f"\nğŸ“ˆ å¤„ç†å®Œæˆ:")
    print(f"   æ€»è¡Œæ•°: {total_lines:,}")
    print(f"   æ€»å¥å­æ•°: {total_sentences:,}")
    print(f"   åŒ¹é…å¥å­æ•°: {len(matching_sentences):,}")
    
    # ä¿å­˜ç»“æœ
    output_file = '/Users/terry/Downloads/video2speech.github.io/video2speech.github.io/matching_sentences.txt'
    with open(output_file, 'w', encoding='utf-8') as f:
        for sentence in matching_sentences:
            f.write(sentence + '\n')
    
    print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: matching_sentences.txt")
    
    # æ˜¾ç¤ºå‰10ä¸ªåŒ¹é…çš„å¥å­ä½œä¸ºç¤ºä¾‹
    print(f"\nğŸ“‹ å‰10ä¸ªåŒ¹é…å¥å­ç¤ºä¾‹:")
    print("-" * 50)
    for i, sentence in enumerate(matching_sentences[:10], 1):
        print(f"{i:2d}. {sentence}")
    
    return matching_sentences

if __name__ == "__main__":
    sentences = process_movie_lines()


