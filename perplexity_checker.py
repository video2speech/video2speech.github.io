#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os
import torch
import numpy as np
from transformers import GPT2LMHeadModel, GPT2Tokenizer, AutoTokenizer, AutoModelForCausalLM
import warnings
warnings.filterwarnings("ignore")

class PerplexityChecker:
    def __init__(self, model_name="gpt2"):
        """
        åˆå§‹åŒ–å›°æƒ‘åº¦æ£€æŸ¥å™¨
        å¯é€‰æ¨¡å‹:
        - "gpt2" (å°æ¨¡å‹ï¼Œå¿«é€Ÿ)
        - "gpt2-medium" (ä¸­ç­‰æ¨¡å‹)
        - "gpt2-large" (å¤§æ¨¡å‹ï¼Œæ›´å‡†ç¡®ä½†æ…¢)
        - "microsoft/DialoGPT-medium" (å¯¹è¯æ¨¡å‹)
        """
        print(f"ğŸ”„ åŠ è½½è¯­è¨€æ¨¡å‹: {model_name}")
        self.model_name = model_name
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        try:
            # åŠ è½½tokenizerå’Œæ¨¡å‹
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModelForCausalLM.from_pretrained(model_name)
            
            # è®¾ç½®pad tokenï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            self.model.to(self.device)
            self.model.eval()
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ’¡ è¯·ç¡®ä¿å®‰è£…äº†transformerså’Œtorch:")
            print("   pip install transformers torch")
            raise
    
    def load_sentences(self, filename="selected_sentences_analyzer.json"):
        """åŠ è½½å¥å­æ•°æ®"""
        if os.path.exists(filename):
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    sentences = json.load(f)
                print(f"ğŸ“ åŠ è½½äº† {len(sentences)} ä¸ªå¥å­")
                return sentences
            except Exception as e:
                print(f"âŒ åŠ è½½å¥å­æ–‡ä»¶å¤±è´¥: {e}")
                return []
        else:
            print(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶: {filename}")
            return []
    
    def calculate_perplexity(self, text):
        """è®¡ç®—å•ä¸ªå¥å­çš„å›°æƒ‘åº¦"""
        try:
            # ç¼–ç æ–‡æœ¬
            encodings = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=512)
            input_ids = encodings.input_ids.to(self.device)
            
            # è®¡ç®—å›°æƒ‘åº¦
            with torch.no_grad():
                outputs = self.model(input_ids, labels=input_ids)
                loss = outputs.loss
                perplexity = torch.exp(loss).item()
            
            return perplexity, loss.item()
            
        except Exception as e:
            print(f"âŒ è®¡ç®—å›°æƒ‘åº¦å¤±è´¥: {text[:50]}... - {e}")
            return float('inf'), float('inf')
    
    def batch_calculate_perplexity(self, sentences, batch_size=8):
        """æ‰¹é‡è®¡ç®—å›°æƒ‘åº¦"""
        results = []
        total = len(sentences)
        
        print(f"\nğŸ”„ å¼€å§‹è®¡ç®— {total} ä¸ªå¥å­çš„å›°æƒ‘åº¦...")
        print(f"ğŸ“Š æ‰¹å¤„ç†å¤§å°: {batch_size}")
        
        for i in range(0, total, batch_size):
            batch = sentences[i:i+batch_size]
            batch_results = []
            
            for j, sentence in enumerate(batch):
                current_idx = i + j + 1
                print(f"â³ å¤„ç†ä¸­ ({current_idx}/{total}): {sentence[:50]}{'...' if len(sentence) > 50 else ''}")
                
                perplexity, loss = self.calculate_perplexity(sentence)
                
                batch_results.append({
                    'index': current_idx,
                    'sentence': sentence,
                    'perplexity': perplexity,
                    'loss': loss,
                    'length': len(sentence.split())  # è¯æ•°
                })
            
            results.extend(batch_results)
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = (i + len(batch)) / total * 100
            print(f"ğŸ“ˆ è¿›åº¦: {progress:.1f}% ({i + len(batch)}/{total})")
        
        return results
    
    def analyze_results(self, results):
        """åˆ†æå›°æƒ‘åº¦ç»“æœ"""
        if not results:
            print("âŒ æ²¡æœ‰ç»“æœå¯åˆ†æ")
            return
        
        # è¿‡æ»¤æ‰æ— æ•ˆç»“æœ
        valid_results = [r for r in results if r['perplexity'] != float('inf')]
        
        if not valid_results:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å›°æƒ‘åº¦è®¡ç®—ç»“æœ")
            return
        
        perplexities = [r['perplexity'] for r in valid_results]
        
        print("\n" + "=" * 80)
        print("ğŸ“Š å›°æƒ‘åº¦åˆ†æç»“æœ")
        print("=" * 80)
        
        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“ˆ ç»Ÿè®¡æ‘˜è¦:")
        print(f"   æ€»å¥å­æ•°: {len(results)}")
        print(f"   æœ‰æ•ˆè®¡ç®—: {len(valid_results)}")
        print(f"   å¹³å‡å›°æƒ‘åº¦: {np.mean(perplexities):.2f}")
        print(f"   ä¸­ä½æ•°å›°æƒ‘åº¦: {np.median(perplexities):.2f}")
        print(f"   æœ€ä½å›°æƒ‘åº¦: {np.min(perplexities):.2f}")
        print(f"   æœ€é«˜å›°æƒ‘åº¦: {np.max(perplexities):.2f}")
        print(f"   æ ‡å‡†å·®: {np.std(perplexities):.2f}")
        
        # æŒ‰å›°æƒ‘åº¦æ’åºï¼ˆä»ä½åˆ°é«˜ï¼Œä½å›°æƒ‘åº¦è¡¨ç¤ºæ›´è‡ªç„¶ï¼‰
        sorted_results = sorted(valid_results, key=lambda x: x['perplexity'])
        
        # æ˜¾ç¤ºæœ€è‡ªç„¶çš„å¥å­ï¼ˆä½å›°æƒ‘åº¦ï¼‰
        print(f"\nğŸŒŸ æœ€è‡ªç„¶çš„å¥å­ (ä½å›°æƒ‘åº¦):")
        print("-" * 60)
        for i, result in enumerate(sorted_results[:10], 1):
            print(f"{i:2d}. å›°æƒ‘åº¦: {result['perplexity']:6.2f} | {result['sentence']}")
        
        # æ˜¾ç¤ºæœ€ä¸è‡ªç„¶çš„å¥å­ï¼ˆé«˜å›°æƒ‘åº¦ï¼‰
        print(f"\nâš ï¸  æœ€ä¸è‡ªç„¶çš„å¥å­ (é«˜å›°æƒ‘åº¦):")
        print("-" * 60)
        for i, result in enumerate(sorted_results[-10:], 1):
            print(f"{i:2d}. å›°æƒ‘åº¦: {result['perplexity']:6.2f} | {result['sentence']}")
        
        return sorted_results
    
    def save_results(self, results, filename="perplexity_report.json"):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        try:
            # ä¿å­˜JSONæ ¼å¼
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜å¯è¯»æ–‡æœ¬æ ¼å¼
            txt_filename = filename.replace('.json', '.txt')
            with open(txt_filename, 'w', encoding='utf-8') as f:
                f.write("å¥å­å›°æƒ‘åº¦åˆ†ææŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"æ¨¡å‹: {self.model_name}\n")
                f.write(f"æ€»å¥å­æ•°: {len(results)}\n\n")
                
                # æŒ‰å›°æƒ‘åº¦æ’åº
                sorted_results = sorted([r for r in results if r['perplexity'] != float('inf')], 
                                      key=lambda x: x['perplexity'])
                
                f.write("æ‰€æœ‰å¥å­çš„å›°æƒ‘åº¦ (æŒ‰å›°æƒ‘åº¦æ’åº):\n")
                f.write("-" * 50 + "\n")
                
                for result in sorted_results:
                    f.write(f"\nå›°æƒ‘åº¦: {result['perplexity']:6.2f} | è¯æ•°: {result['length']:2d} | {result['sentence']}\n")
            
            print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°:")
            print(f"   ğŸ“„ {filename} (JSONæ ¼å¼)")
            print(f"   ğŸ“„ {txt_filename} (æ–‡æœ¬æ ¼å¼)")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

def main():
    print("ğŸ¯ å¥å­å›°æƒ‘åº¦æ£€æŸ¥å™¨")
    print("=" * 50)
    
    # é€‰æ‹©æ¨¡å‹
    models = {
        "1": "gpt2",
        "2": "gpt2-medium", 
        "3": "microsoft/DialoGPT-medium"
    }
    
    print("ğŸ“š å¯ç”¨æ¨¡å‹:")
    print("   1. GPT-2 (å°æ¨¡å‹ï¼Œå¿«é€Ÿ)")
    print("   2. GPT-2 Medium (ä¸­ç­‰æ¨¡å‹)")
    print("   3. DialoGPT Medium (å¯¹è¯æ¨¡å‹)")
    
    choice = input("\né€‰æ‹©æ¨¡å‹ (1-3, é»˜è®¤1): ").strip() or "1"
    model_name = models.get(choice, "gpt2")
    
    try:
        # åˆå§‹åŒ–æ£€æŸ¥å™¨
        checker = PerplexityChecker(model_name)
        
        # åŠ è½½å¥å­
        sentences = checker.load_sentences()
        if not sentences:
            return
        
        # æ‰¹é‡è®¡ç®—å›°æƒ‘åº¦
        batch_size = int(input(f"\næ‰¹å¤„ç†å¤§å° (é»˜è®¤4): ").strip() or "4")
        results = checker.batch_calculate_perplexity(sentences, batch_size)
        
        # åˆ†æç»“æœ
        sorted_results = checker.analyze_results(results)
        
        # ä¿å­˜ç»“æœ
        if sorted_results:
            save_choice = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜ç»“æœ? (y/N): ").strip().lower()
            if save_choice in ['y', 'yes']:
                checker.save_results(results)
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        print("ğŸ’¡ å¦‚æœæ˜¯æ¨¡å‹åŠ è½½é—®é¢˜ï¼Œè¯·å°è¯•:")
        print("   pip install transformers torch")
        print("   æˆ–é€‰æ‹©æ›´å°çš„æ¨¡å‹")

if __name__ == "__main__":
    main()


