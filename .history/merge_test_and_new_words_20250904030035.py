#!/usr/bin/env python3
# -*- coding: utf-8 -*-

def merge_vocabularies():
    """åˆå¹¶ test.txt å’Œæ–°è¯æ±‡ï¼Œå»é‡å¹¶ä¿æŒé¡ºåº"""
    
    print("=" * 80)
    print("åˆå¹¶è¯æ±‡è¡¨ - test.txt + æ–°è¯æ±‡")
    print("=" * 80)
    
    # è¯»å– test.txt ä¸­çš„è¯æ±‡
    try:
        with open('test.txt', 'r', encoding='utf-8') as f:
            test_words = [word.strip().lower() for word in f.readlines() if word.strip()]
        
        print(f"test.txt è¯æ±‡æ•°: {len(test_words)}")
        
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° test.txt æ–‡ä»¶")
        return
    
    # æ–°å¢çš„è¯æ±‡ï¼ˆè½¬æ¢ä¸ºå°å†™ï¼‰
    new_words_raw = [
        "Am", "Are", "Bad", "Bring", "Clean", "Closer", "Comfortable", "Coming", "Computer", "Do",
        "Faith", "Family", "Feel", "Glasses", "Going", "Good", "Goodbye", "Have", "Hello", "Help",
        "Here", "Hope", "How", "Hungry", "I", "Is", "It", "Like", "Music", "My",
        "Need", "No", "Not", "Nurse", "Okay", "Outside", "Please", "Right", "Success", "Tell",
        "That", "They", "Thirsty", "Tired", "Up", "Very", "What", "Where", "Yes", "You"
    ]
    
    new_words = [word.lower() for word in new_words_raw]
    
    print(f"æ–°å¢è¯æ±‡: {len(new_words)} ä¸ª")
    
    # åˆå¹¶è¯æ±‡è¡¨ï¼Œä¿æŒåŸæ¥çš„é¡ºåºï¼Œå»é‡
    merged_words = []
    seen = set()
    
    # é¦–å…ˆæ·»åŠ  test.txt çš„è¯æ±‡
    for word in test_words:
        if word not in seen:
            merged_words.append(word)
            seen.add(word)
    
    # ç„¶åæ·»åŠ æ–°è¯æ±‡ï¼ˆå¦‚æœä¸é‡å¤çš„è¯ï¼‰
    new_added = []
    for word in new_words:
        if word not in seen:
            merged_words.append(word)
            seen.add(word)
            new_added.append(word)
    
    print(f"å®é™…æ–°å¢: {len(new_added)} ä¸ªè¯")
    print(f"é‡å¤è¯æ±‡: {len(new_words) - len(new_added)} ä¸ª")
    print(f"åˆå¹¶åæ€»æ•°: {len(merged_words)} ä¸ªè¯")
    
    # æ˜¾ç¤ºæ–°å¢çš„è¯æ±‡
    if new_added:
        print(f"\nğŸ†• æ–°å¢çš„è¯æ±‡:")
        for i, word in enumerate(new_added, 1):
            print(f"{i:2d}. {word}")
    
    # æ˜¾ç¤ºé‡å¤çš„è¯æ±‡
    duplicates = [word for word in new_words if word in test_words]
    if duplicates:
        print(f"\nğŸ”„ é‡å¤çš„è¯æ±‡ (å·²å­˜åœ¨äºtest.txtä¸­):")
        for i, word in enumerate(duplicates, 1):
            print(f"{i:2d}. {word}")
    
    # ä¿å­˜åˆå¹¶åçš„è¯æ±‡è¡¨
    output_file = 'merged_vocabulary.txt'
    with open(output_file, 'w', encoding='utf-8') as f:
        for word in merged_words:
            f.write(word + '\n')
    
    print(f"\nâœ… åˆå¹¶å®Œæˆï¼")
    print(f"ğŸ“„ å·²ä¿å­˜åˆ°: {output_file}")
    print(f"ğŸ“Š test.txt: {len(test_words)} + æ–°è¯æ±‡: {len(new_added)} = åˆå¹¶å: {len(merged_words)} ä¸ªè¯")
    
    # æ˜¾ç¤ºåˆå¹¶åçš„å‰30ä¸ªè¯
    print(f"\nğŸ“ åˆå¹¶åè¯æ±‡è¡¨å‰30ä¸ªè¯:")
    for i, word in enumerate(merged_words[:30], 1):
        print(f"{i:2d}. {word}")
    
    if len(merged_words) > 30:
        print(f"... è¿˜æœ‰ {len(merged_words) - 30} ä¸ªè¯")
    
    # åˆ›å»ºç»Ÿè®¡æŠ¥å‘Š
    stats_file = 'vocabulary_merge_stats.txt'
    with open(stats_file, 'w', encoding='utf-8') as f:
        f.write("è¯æ±‡è¡¨åˆå¹¶ç»Ÿè®¡æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"æºæ–‡ä»¶1: test.txt\n")
        f.write(f"æºæ–‡ä»¶1è¯æ±‡æ•°: {len(test_words)}\n\n")
        f.write(f"æ–°å¢è¯æ±‡æ•°: {len(new_words)}\n")
        f.write(f"å®é™…æ–°å¢: {len(new_added)}\n")
        f.write(f"é‡å¤è¯æ±‡: {len(duplicates)}\n\n")
        f.write(f"åˆå¹¶åæ€»è¯æ±‡æ•°: {len(merged_words)}\n\n")
        
        f.write("æ–°å¢çš„è¯æ±‡:\n")
        for word in new_added:
            f.write(f"  {word}\n")
        
        f.write("\né‡å¤çš„è¯æ±‡:\n")
        for word in duplicates:
            f.write(f"  {word}\n")
        
        f.write(f"\nå®Œæ•´è¯æ±‡è¡¨:\n")
        for i, word in enumerate(merged_words, 1):
            f.write(f"{i:3d}. {word}\n")
    
    print(f"ğŸ“Š ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {stats_file}")
    
    return merged_words

def main():
    """ä¸»å‡½æ•°"""
    merged_words = merge_vocabularies()
    
    if merged_words:
        print(f"\nğŸ¯ è¯æ±‡è¡¨åˆå¹¶å®Œæˆï¼")
        print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: merged_vocabulary.txt")
        print(f"ğŸ”¢ æ€»è®¡: {len(merged_words)} ä¸ªå”¯ä¸€è¯æ±‡")

if __name__ == "__main__":
    main()
