#!/usr/bin/env python3
# -*- coding: utf-8 -*-

def merge_wordlists():
    """åˆå¹¶è¯æ±‡è¡¨ï¼Œå»é‡å¹¶ä¿æŒåŸæ¥çš„é¡ºåº"""
    
    print("=" * 80)
    print("åˆå¹¶è¯æ±‡è¡¨ - å»é‡å¹¶ä¿æŒé¡ºåº")
    print("=" * 80)
    
    # è¯»å–åŸæ¥çš„ newtopwords.txt
    try:
        with open('others/newtopwords.txt', 'r', encoding='utf-8') as f:
            original_words = [word.strip().lower() for word in f.readlines() if word.strip()]
        
        print(f"åŸå§‹è¯æ±‡è¡¨: {len(original_words)} ä¸ªè¯")
        
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° others/newtopwords.txt")
        return
    
    # æ–°å¢çš„è¯æ±‡ï¼ˆè½¬æ¢ä¸ºå°å†™ï¼‰
    new_words_raw = [
        "Am", "Are", "Bad", "Bring", "Clean", "Closer", "Comfortable", "Coming", "Computer", "Do",
        "Faith", "Family", "Feel", "Glasses", "Going", "Good", "Goodbye", "Have", "Hello", "Help",
        "Here", "Hope", "How", "Hungry", "I", "Is", "It", "Like", "Music", "My",
        "Need", "No", "Not", "Nurse", "Okay", "Outside", "Please", "Right", "Success", "Tell",
        "That", "They", "Thirsty", "Tired", "Up", "Very", "What", "Where", "Yes", "You"
    ]
    
    new_words = [word.lower() for word in new_words_raw]
    
    print(f"æ–°å¢è¯æ±‡: {len(new_words)} ä¸ªè¯")
    
    # åˆå¹¶è¯æ±‡è¡¨ï¼Œä¿æŒåŸæ¥çš„é¡ºåºï¼Œå»é‡
    merged_words = []
    seen = set()
    
    # é¦–å…ˆæ·»åŠ åŸæ¥çš„è¯æ±‡
    for word in original_words:
        if word not in seen:
            merged_words.append(word)
            seen.add(word)
    
    # ç„¶åæ·»åŠ æ–°è¯æ±‡ï¼ˆå¦‚æœä¸é‡å¤çš„è¯ï¼‰
    new_added = []
    for word in new_words:
        if word not in seen:
            merged_words.append(word)
            seen.add(word)
            new_added.append(word)
    
    print(f"å®é™…æ–°å¢: {len(new_added)} ä¸ªè¯")
    print(f"é‡å¤è¯æ±‡: {len(new_words) - len(new_added)} ä¸ª")
    print(f"åˆå¹¶åæ€»æ•°: {len(merged_words)} ä¸ªè¯")
    
    # æ˜¾ç¤ºæ–°å¢çš„è¯æ±‡
    if new_added:
        print(f"\næ–°å¢çš„è¯æ±‡:")
        for i, word in enumerate(new_added, 1):
            print(f"{i:2d}. {word}")
    
    # æ˜¾ç¤ºé‡å¤çš„è¯æ±‡
    duplicates = [word for word in new_words if word in original_words]
    if duplicates:
        print(f"\né‡å¤çš„è¯æ±‡ (å·²å­˜åœ¨):")
        for i, word in enumerate(duplicates, 1):
            print(f"{i:2d}. {word}")
    
    # ä¿å­˜åˆå¹¶åçš„è¯æ±‡è¡¨
    output_file = 'others/newtopwords.txt'
    with open(output_file, 'w', encoding='utf-8') as f:
        for word in merged_words:
            f.write(word + '\n')
    
    print(f"\nâœ… åˆå¹¶å®Œæˆï¼")
    print(f"ğŸ“„ å·²æ›´æ–°: {output_file}")
    print(f"ğŸ“Š åŸå§‹: {len(original_words)} â†’ åˆå¹¶å: {len(merged_words)} ä¸ªè¯")
    
    # æ˜¾ç¤ºåˆå¹¶åçš„å‰20ä¸ªè¯
    print(f"\nğŸ“ åˆå¹¶åè¯æ±‡è¡¨å‰20ä¸ªè¯:")
    for i, word in enumerate(merged_words[:20], 1):
        print(f"{i:2d}. {word}")
    
    if len(merged_words) > 20:
        print(f"... è¿˜æœ‰ {len(merged_words) - 20} ä¸ªè¯")
    
    return merged_words

def main():
    """ä¸»å‡½æ•°"""
    merged_words = merge_wordlists()
    
    if merged_words:
        print(f"\nğŸ¯ è¯æ±‡è¡¨å·²æˆåŠŸæ›´æ–°ï¼")
        print(f"å¯ä»¥ä½¿ç”¨æ–°çš„è¯æ±‡è¡¨é‡æ–°ç­›é€‰å¥å­äº†ã€‚")

if __name__ == "__main__":
    main()
