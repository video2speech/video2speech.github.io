#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import csv

def create_word_frequency_summary():
    """åˆ›å»ºè¯é¢‘åˆ†ææ€»ç»“"""
    
    print("=" * 80)
    print("ğŸ“Š filtered_sentences_150_words_clean.txt è¯é¢‘åˆ†ææ€»ç»“")
    print("=" * 80)
    
    # è¯»å–CSVæ•°æ®
    try:
        with open('filtered_sentences_150_words_frequency.csv', 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            word_data = list(reader)
        
        print(f"âœ… æˆåŠŸè¯»å– {len(word_data)} ä¸ªè¯æ±‡çš„é¢‘ç‡æ•°æ®\n")
        
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ°è¯é¢‘CSVæ–‡ä»¶")
        return
    
    # åŸºæœ¬ç»Ÿè®¡
    total_words = int(word_data[-1]['ç´¯ç§¯é¢‘æ¬¡'])
    unique_words = len(word_data)
    
    print(f"ğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
    print(f"   ğŸ“„ æ•°æ®æº: filtered_sentences_150_words_clean.txt")
    print(f"   ğŸ“ å¥å­æ€»æ•°: 3,234ä¸ª")
    print(f"   ğŸ”¤ æ€»è¯æ±‡æ•°: {total_words:,}ä¸ª (ä¸åŒ…æ‹¬æ ‡ç‚¹ç¬¦å·)")
    print(f"   ğŸ¯ å”¯ä¸€è¯æ±‡æ•°: {unique_words}ä¸ª")
    print(f"   ğŸ“ å¹³å‡æ¯å¥è¯æ•°: 5.03ä¸ª")
    print(f"   âœ… è¯æ±‡è¡¨è¦†ç›–ç‡: 100% (æ‰€æœ‰è¯éƒ½åœ¨150è¯æ±‡è¡¨ä¸­)")
    
    # é«˜é¢‘è¯åˆ†æ
    print(f"\nğŸ” TOP 10 é«˜é¢‘è¯æ±‡:")
    print(f"{'æ’å':<4} {'è¯æ±‡':<12} {'é¢‘æ¬¡':<6} {'å æ¯”':<8} {'ç´¯ç§¯å æ¯”':<8}")
    print("-" * 45)
    
    for i in range(min(10, len(word_data))):
        word = word_data[i]
        print(f"{word['æ’å']:<4} {word['è¯æ±‡']:<12} {word['é¢‘æ¬¡']:<6} "
              f"{word['å æ¯”(%)']:<7}% {word['ç´¯ç§¯å æ¯”(%)']:<7}%")
    
    # é¢‘ç‡åˆ†å¸ƒåˆ†æ
    freq_counts = {}
    for word in word_data:
        count = int(word['é¢‘æ¬¡'])
        if count == 1:
            freq_counts['1æ¬¡'] = freq_counts.get('1æ¬¡', 0) + 1
        elif 2 <= count <= 5:
            freq_counts['2-5æ¬¡'] = freq_counts.get('2-5æ¬¡', 0) + 1
        elif 6 <= count <= 10:
            freq_counts['6-10æ¬¡'] = freq_counts.get('6-10æ¬¡', 0) + 1
        elif 11 <= count <= 20:
            freq_counts['11-20æ¬¡'] = freq_counts.get('11-20æ¬¡', 0) + 1
        elif 21 <= count <= 50:
            freq_counts['21-50æ¬¡'] = freq_counts.get('21-50æ¬¡', 0) + 1
        elif 51 <= count <= 100:
            freq_counts['51-100æ¬¡'] = freq_counts.get('51-100æ¬¡', 0) + 1
        else:
            freq_counts['>100æ¬¡'] = freq_counts.get('>100æ¬¡', 0) + 1
    
    print(f"\nğŸ“Š è¯é¢‘åˆ†å¸ƒ:")
    for freq_range, count in freq_counts.items():
        percentage = (count / unique_words) * 100
        print(f"   {freq_range:<8}: {count:3d}ä¸ªè¯ ({percentage:4.1f}%)")
    
    # è¦†ç›–ç‡åˆ†æ
    print(f"\nğŸ¯ é«˜é¢‘è¯è¦†ç›–ç‡åˆ†æ:")
    coverage_points = [5, 10, 20, 30, 50, 80, 100, 141]
    
    for point in coverage_points:
        if point <= len(word_data):
            cumulative_pct = float(word_data[point-1]['ç´¯ç§¯å æ¯”(%)'])
            print(f"   å‰{point:3d}ä¸ªé«˜é¢‘è¯è¦†ç›–: {cumulative_pct:5.1f}% çš„æ€»è¯é¢‘")
    
    # æ ¸å¿ƒè¯æ±‡åˆ†æ
    print(f"\nğŸ’ æ ¸å¿ƒè¯æ±‡åˆ†æ:")
    
    # å‰10ä¸ªè¯æ±‡ï¼ˆè¶…é«˜é¢‘ï¼‰
    top_10_words = [word_data[i]['è¯æ±‡'] for i in range(10)]
    top_10_coverage = float(word_data[9]['ç´¯ç§¯å æ¯”(%)'])
    print(f"   ğŸ¥‡ è¶…é«˜é¢‘è¯æ±‡ (å‰10ä¸ª): {', '.join(top_10_words)}")
    print(f"      è¦†ç›–ç‡: {top_10_coverage:.1f}%")
    
    # 11-30ä¸ªè¯æ±‡ï¼ˆé«˜é¢‘ï¼‰
    high_freq_words = [word_data[i]['è¯æ±‡'] for i in range(10, 30)]
    high_freq_coverage = float(word_data[29]['ç´¯ç§¯å æ¯”(%)']) - top_10_coverage
    print(f"   ğŸ¥ˆ é«˜é¢‘è¯æ±‡ (11-30ä½): {', '.join(high_freq_words[:10])}...")
    print(f"      é¢å¤–è¦†ç›–ç‡: {high_freq_coverage:.1f}%")
    
    # 31-80ä¸ªè¯æ±‡ï¼ˆä¸­é¢‘ï¼‰
    mid_freq_coverage = float(word_data[79]['ç´¯ç§¯å æ¯”(%)']) - float(word_data[29]['ç´¯ç§¯å æ¯”(%)'])
    print(f"   ğŸ¥‰ ä¸­é¢‘è¯æ±‡ (31-80ä½): 50ä¸ªè¯æ±‡")
    print(f"      é¢å¤–è¦†ç›–ç‡: {mid_freq_coverage:.1f}%")
    
    # 81-141ä¸ªè¯æ±‡ï¼ˆä½é¢‘ï¼‰
    low_freq_coverage = 100.0 - float(word_data[79]['ç´¯ç§¯å æ¯”(%)'])
    print(f"   ğŸ“ ä½é¢‘è¯æ±‡ (81-141ä½): 61ä¸ªè¯æ±‡")
    print(f"      é¢å¤–è¦†ç›–ç‡: {low_freq_coverage:.1f}%")
    
    # ç‰¹æ®Šè¯æ±‡åˆ†æ
    print(f"\nğŸ” ç‰¹æ®Šè¯æ±‡åˆ†æ:")
    
    # æœ€ä½é¢‘çš„è¯æ±‡
    lowest_freq_words = []
    for i in range(len(word_data)-1, -1, -1):
        freq = int(word_data[i]['é¢‘æ¬¡'])
        if freq <= 5:
            lowest_freq_words.append(f"{word_data[i]['è¯æ±‡']}({freq})")
        if len(lowest_freq_words) >= 10:
            break
    
    if lowest_freq_words:
        print(f"   ğŸ“‰ æœ€ä½é¢‘è¯æ±‡: {', '.join(reversed(lowest_freq_words))}")
    
    # æ•ˆç‡åˆ†æ
    print(f"\nâš¡ æ•ˆç‡åˆ†æ:")
    print(f"   ğŸ“Š è¯æ±‡åˆ©ç”¨ç‡: 100% (141/149ä¸ªè¯æ±‡è¡¨è¯æ±‡è¢«ä½¿ç”¨)")
    print(f"   ğŸ¯ æ ¸å¿ƒè¯æ±‡æ•ˆç‡: å‰20ä¸ªè¯æ±‡è¦†ç›– {float(word_data[19]['ç´¯ç§¯å æ¯”(%)']):.1f}% çš„ä½¿ç”¨é¢‘ç‡")
    print(f"   ğŸ’ª è¡¨è¾¾èƒ½åŠ›: ç”¨141ä¸ªè¯æ±‡æ„å»ºäº†3,234ä¸ªä¸åŒå¥å­")
    print(f"   ğŸ”„ è¯æ±‡å¤ç”¨ç‡: å¹³å‡æ¯ä¸ªè¯æ±‡ä½¿ç”¨ {total_words/unique_words:.1f} æ¬¡")
    
    # è¯­è¨€å­¦åˆ†æ
    print(f"\nğŸ“ è¯­è¨€å­¦ç‰¹å¾:")
    
    # åˆ†æè¯æ€§ï¼ˆåŸºäºå¸¸è§è¯æ±‡ï¼‰
    pronouns = ['i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them']
    verbs = ['do', 'did', 'have', 'get', 'go', 'say', 'tell', 'think', 'want', 'know', 'see', 'come', 'put']
    function_words = ['to', 'that', 'is', 'are', 'the', 'a', 'an', 'and', 'or', 'but', 'if', 'when', 'where']
    
    pronoun_count = sum(int(word['é¢‘æ¬¡']) for word in word_data if word['è¯æ±‡'] in pronouns)
    verb_count = sum(int(word['é¢‘æ¬¡']) for word in word_data if word['è¯æ±‡'] in verbs)
    function_count = sum(int(word['é¢‘æ¬¡']) for word in word_data if word['è¯æ±‡'] in function_words)
    
    print(f"   ğŸ‘¥ ä»£è¯ä½¿ç”¨é¢‘ç‡: {pronoun_count/total_words*100:.1f}% (å¯¹è¯æ€§å¼º)")
    print(f"   ğŸƒ åŠ¨è¯ä½¿ç”¨é¢‘ç‡: {verb_count/total_words*100:.1f}% (åŠ¨ä½œå¯¼å‘)")
    print(f"   ğŸ”— åŠŸèƒ½è¯é¢‘ç‡: {function_count/total_words*100:.1f}% (è¯­æ³•å®Œæ•´)")
    
    print(f"\nâœ… æ€»ç»“:")
    print(f"   ğŸ¯ è¿™æ˜¯ä¸€ä¸ªé«˜è´¨é‡çš„ç²¾ç®€è‹±è¯­å¥å­æ•°æ®é›†")
    print(f"   ğŸ’ ä½¿ç”¨141ä¸ªæ ¸å¿ƒè¯æ±‡æ„å»ºäº†3,234ä¸ªè¡¨è¾¾ä¸°å¯Œçš„å¥å­")
    print(f"   ğŸš€ é€‚åˆè‹±è¯­å­¦ä¹ ã€è¯­éŸ³åˆæˆå’Œè‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨")
    print(f"   â­ è¯æ±‡åˆ†å¸ƒåˆç†ï¼Œæ ¸å¿ƒé«˜é¢‘è¯å ä¸»å¯¼åœ°ä½")

def main():
    """ä¸»å‡½æ•°"""
    create_word_frequency_summary()

if __name__ == "__main__":
    main()
